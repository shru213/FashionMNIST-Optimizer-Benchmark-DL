{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "253c81a0-45d3-47a4-8c53-a75d1ae8aba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor \n",
    "from torchvision import datasets\n",
    "from torch import nn,optim\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad04610e-d371-4c87-b2b8-751e1d61c64c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 26.4M/26.4M [00:04<00:00, 5.51MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 29.5k/29.5k [00:00<00:00, 2.28MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 4.42M/4.42M [00:00<00:00, 5.36MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 5.15k/5.15k [00:00<?, ?B/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data = datasets.FashionMNIST(\n",
    "    root='data',\n",
    "    download=True,\n",
    "    train=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root='data',\n",
    "    download=True,\n",
    "    train=False,\n",
    "    transform=ToTensor()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "988fc07b-a7d8-409f-a1e9-28b0ab2a1331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28]) torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(dataset=train_data, shuffle=True, batch_size=64)\n",
    "test_loader = DataLoader(dataset=test_data, shuffle=True, batch_size=64)\n",
    "\n",
    "for images, labels in train_loader:\n",
    "    print(images.shape, labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "18108abe-25e8-4dc6-974b-a7dd88b5b982",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dress'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]\n",
    "\n",
    "classes[labels[7].item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ef568621-92fe-40d2-bd1b-9b24ad3d1f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(2,2))\n",
    "plt.imshow(images[7].squeeze(), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "78a090be-9d8a-44b0-9e1e-07982ddc9f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClothesClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(28*28, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128,64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64,10)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.network(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47a5c64-6479-41de-beed-260d49597070",
   "metadata": {},
   "source": [
    "## SGD optimizer (without momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4c1ed0b5-9987-4f6a-995a-d0eddbab95fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ClothesClassifier()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "089a85a7-2872-4f06-a715-e9e436cf70d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 0, Loss: 2.312\n",
      "Batch: 100, Loss: 2.288\n",
      "Batch: 200, Loss: 2.277\n",
      "Batch: 300, Loss: 2.261\n",
      "Batch: 400, Loss: 2.261\n",
      "Batch: 500, Loss: 2.255\n",
      "Batch: 600, Loss: 2.254\n",
      "Batch: 700, Loss: 2.238\n",
      "Batch: 800, Loss: 2.238\n",
      "Batch: 900, Loss: 2.234\n",
      "Batch: 0, Loss: 2.202\n",
      "Batch: 100, Loss: 2.193\n",
      "Batch: 200, Loss: 2.204\n",
      "Batch: 300, Loss: 2.176\n",
      "Batch: 400, Loss: 2.155\n",
      "Batch: 500, Loss: 2.129\n",
      "Batch: 600, Loss: 2.118\n",
      "Batch: 700, Loss: 2.108\n",
      "Batch: 800, Loss: 2.076\n",
      "Batch: 900, Loss: 2.042\n"
     ]
    }
   ],
   "source": [
    "epochs = 2\n",
    "model.train()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for batch, (images,labels) in enumerate(train_loader):\n",
    "        pred = model(images)\n",
    "        loss = loss_fn(pred, labels)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            print(f\"Batch: {batch}, Loss: {loss.item():0.3f}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3a73ee-1145-4191-a043-f129a5e80403",
   "metadata": {},
   "source": [
    "#### SGD --> Loss: 2.042"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dcf052a-5a48-4ab3-8aae-45d7c1dc09de",
   "metadata": {},
   "source": [
    "## SGD optimizer (with momemtum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1372c47e-e971-4301-bc36-06f684fc6697",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ClothesClassifier()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8f3ae809-8714-45da-85ee-92b3e2732bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 0, Loss: 2.301\n",
      "Batch: 100, Loss: 2.231\n",
      "Batch: 200, Loss: 2.141\n",
      "Batch: 300, Loss: 1.946\n",
      "Batch: 400, Loss: 1.517\n",
      "Batch: 500, Loss: 1.270\n",
      "Batch: 600, Loss: 1.167\n",
      "Batch: 700, Loss: 1.008\n",
      "Batch: 800, Loss: 0.899\n",
      "Batch: 900, Loss: 0.847\n",
      "Batch: 0, Loss: 0.803\n",
      "Batch: 100, Loss: 0.767\n",
      "Batch: 200, Loss: 0.806\n",
      "Batch: 300, Loss: 0.714\n",
      "Batch: 400, Loss: 0.833\n",
      "Batch: 500, Loss: 0.717\n",
      "Batch: 600, Loss: 0.922\n",
      "Batch: 700, Loss: 0.563\n",
      "Batch: 800, Loss: 0.649\n",
      "Batch: 900, Loss: 0.556\n"
     ]
    }
   ],
   "source": [
    "epochs = 2\n",
    "model.train()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for batch, (images,labels) in enumerate(train_loader):\n",
    "        pred = model(images)\n",
    "        loss = loss_fn(pred, labels)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            print(f\"Batch: {batch}, Loss: {loss.item():0.3f}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78168edf-089d-40d1-b40f-d3a545835401",
   "metadata": {},
   "source": [
    "#### SGD with momemtum --> Loss: 0.556"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629b1889-05e5-4230-9423-0e8ec467a80a",
   "metadata": {},
   "source": [
    "## Adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9bff885e-3773-48ac-89b6-87ad48e0e484",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ClothesClassifier()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2c787b1a-dc59-4cb4-883b-90d4b4746c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 0, Loss: 2.306\n",
      "Batch: 100, Loss: 0.881\n",
      "Batch: 200, Loss: 0.586\n",
      "Batch: 300, Loss: 0.477\n",
      "Batch: 400, Loss: 0.530\n",
      "Batch: 500, Loss: 0.528\n",
      "Batch: 600, Loss: 0.491\n",
      "Batch: 700, Loss: 0.362\n",
      "Batch: 800, Loss: 0.542\n",
      "Batch: 900, Loss: 0.489\n",
      "Batch: 0, Loss: 0.297\n",
      "Batch: 100, Loss: 0.420\n",
      "Batch: 200, Loss: 0.352\n",
      "Batch: 300, Loss: 0.414\n",
      "Batch: 400, Loss: 0.200\n",
      "Batch: 500, Loss: 0.470\n",
      "Batch: 600, Loss: 0.314\n",
      "Batch: 700, Loss: 0.473\n",
      "Batch: 800, Loss: 0.485\n",
      "Batch: 900, Loss: 0.409\n"
     ]
    }
   ],
   "source": [
    "epochs = 2\n",
    "model.train()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for batch, (images,labels) in enumerate(train_loader):\n",
    "        pred = model(images)\n",
    "        loss = loss_fn(pred, labels)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            print(f\"Batch: {batch}, Loss: {loss.item():0.3f}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2340f2d1-fe27-47b6-92b3-ad6203ae8059",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "all_predicted = []\n",
    "all_labels = []\n",
    "\n",
    "for images, labels in test_loader:\n",
    "    output = model(images)\n",
    "\n",
    "    _, predicted = torch.max(output.data, 1)\n",
    "\n",
    "    all_predicted.extend(predicted.numpy())\n",
    "    all_labels.extend(labels.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "9fb85d51-6fb7-4288-8b50-be38657d8b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.72      0.78      1000\n",
      "           1       0.98      0.96      0.97      1000\n",
      "           2       0.75      0.76      0.75      1000\n",
      "           3       0.86      0.85      0.86      1000\n",
      "           4       0.72      0.82      0.77      1000\n",
      "           5       0.97      0.92      0.94      1000\n",
      "           6       0.64      0.62      0.63      1000\n",
      "           7       0.90      0.95      0.92      1000\n",
      "           8       0.93      0.97      0.95      1000\n",
      "           9       0.95      0.95      0.95      1000\n",
      "\n",
      "    accuracy                           0.85     10000\n",
      "   macro avg       0.86      0.85      0.85     10000\n",
      "weighted avg       0.86      0.85      0.85     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = classification_report(all_labels, all_predicted)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bddc8bd-445d-47eb-b44d-1a2b1a4c2656",
   "metadata": {},
   "source": [
    "#### Adam --> Loss: 0.409\n",
    "#### Accuracy --> 85%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6e6e51-b1cb-46a3-a3a8-2f3668e4d108",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
